{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRYSCxOfw63R"
      },
      "source": [
        "# **Fully Connected Neural Network: A `CUDA` and `C++` Implementation**\n",
        "\n",
        "## **Prepare workspace**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuVjWOoYnS9k",
        "outputId": "8c9dbf4b-d69f-44e4-cd44-2aff4ae1c6ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "%cd /content/drive/MyDrive/Project"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Extract `.gz` data (if needed)**"
      ],
      "metadata": {
        "id": "JxobDUCcMqgs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt_j33LhO3S8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "b8b98d24-f370-4e96-c3f4-8e1f276bfd03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patool\n",
            "  Downloading patool-3.1.0-py2.py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading patool-3.1.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.4/98.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-3.1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO patool: Extracting mnist/t10k-images-idx3-ubyte.gz ...\n",
            "INFO:patool:Extracting mnist/t10k-images-idx3-ubyte.gz ...\n",
            "INFO patool: running /usr/bin/7z e -omnist -- mnist/t10k-images-idx3-ubyte.gz\n",
            "INFO:patool:running /usr/bin/7z e -omnist -- mnist/t10k-images-idx3-ubyte.gz\n",
            "INFO patool: ... mnist/t10k-images-idx3-ubyte.gz extracted to `mnist'.\n",
            "INFO:patool:... mnist/t10k-images-idx3-ubyte.gz extracted to `mnist'.\n",
            "INFO patool: Extracting mnist/t10k-labels-idx1-ubyte.gz ...\n",
            "INFO:patool:Extracting mnist/t10k-labels-idx1-ubyte.gz ...\n",
            "INFO patool: running /usr/bin/7z e -omnist -- mnist/t10k-labels-idx1-ubyte.gz\n",
            "INFO:patool:running /usr/bin/7z e -omnist -- mnist/t10k-labels-idx1-ubyte.gz\n",
            "INFO patool: ... mnist/t10k-labels-idx1-ubyte.gz extracted to `mnist'.\n",
            "INFO:patool:... mnist/t10k-labels-idx1-ubyte.gz extracted to `mnist'.\n",
            "INFO patool: Extracting mnist/train-images-idx3-ubyte.gz ...\n",
            "INFO:patool:Extracting mnist/train-images-idx3-ubyte.gz ...\n",
            "INFO patool: running /usr/bin/7z e -omnist -- mnist/train-images-idx3-ubyte.gz\n",
            "INFO:patool:running /usr/bin/7z e -omnist -- mnist/train-images-idx3-ubyte.gz\n",
            "INFO patool: ... mnist/train-images-idx3-ubyte.gz extracted to `mnist'.\n",
            "INFO:patool:... mnist/train-images-idx3-ubyte.gz extracted to `mnist'.\n",
            "INFO patool: Extracting mnist/train-labels-idx1-ubyte.gz ...\n",
            "INFO:patool:Extracting mnist/train-labels-idx1-ubyte.gz ...\n",
            "INFO patool: running /usr/bin/7z e -omnist -- mnist/train-labels-idx1-ubyte.gz\n",
            "INFO:patool:running /usr/bin/7z e -omnist -- mnist/train-labels-idx1-ubyte.gz\n",
            "INFO patool: ... mnist/train-labels-idx1-ubyte.gz extracted to `mnist'.\n",
            "INFO:patool:... mnist/train-labels-idx1-ubyte.gz extracted to `mnist'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mnist'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Extract data from `.gz`\n",
        "# Only need to run once!\n",
        "!pip install patool\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"mnist/t10k-images-idx3-ubyte.gz\", outdir=\"mnist\")\n",
        "patoolib.extract_archive(\"mnist/t10k-labels-idx1-ubyte.gz\", outdir=\"mnist\")\n",
        "patoolib.extract_archive(\"mnist/train-images-idx3-ubyte.gz\", outdir=\"mnist\")\n",
        "patoolib.extract_archive(\"mnist/train-labels-idx1-ubyte.gz\", outdir=\"mnist\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHDo9SlfxRNB"
      },
      "source": [
        "## **Edit `Makefile`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMaJmzUCqeX5",
        "outputId": "bd47fe4b-6d2e-4c68-d9b3-3ecadcfeeb40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Makefile\n"
          ]
        }
      ],
      "source": [
        "%%writefile Makefile\n",
        "\n",
        "# Compilers\n",
        "CXX := g++\n",
        "CXX_FLAGS := -std=c++17 -ggdb\n",
        "NVCC := nvcc\n",
        "\n",
        "# Folders\n",
        "BIN := bin\n",
        "SRC := src\n",
        "INCLUDE := include\n",
        "\n",
        "EXECUTABLE := nn_main\n",
        "\n",
        "all: $(BIN)/$(EXECUTABLE)\n",
        "\n",
        "run: clean all\n",
        "\tclear\n",
        "\t./$(BIN)/$(EXECUTABLE)\n",
        "\n",
        "$(BIN)/$(EXECUTABLE): $(SRC)/*.cu $(SRC)/*.cpp\n",
        "\t$(NVCC) -I $(INCLUDE) $^ -o $@\n",
        "\n",
        "clean:\n",
        "\t-rm $(BIN)/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z93_j8BAOv8k"
      },
      "source": [
        "## **Compile and run**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_b83tTQvwaW",
        "outputId": "20bcb068-99c7-46ef-cdd4-88f5b539538f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc -I include src/main.cu src/nn.cu src/utils_device.cu src/data.cpp src/utils_host.cpp -o bin/nn_main\n"
          ]
        }
      ],
      "source": [
        "# Compile\n",
        "!make"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Run with different config**\n",
        "> To run the program:\n",
        "> `./main <#-neurons> <#-epochs> <learning-rate> <mode>` \\\n",
        "> Set `mode` to `0` to not use optimized GPU."
      ],
      "metadata": {
        "id": "6XVc-Ve3VZzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"BASELINE GPU TEST...\"\n",
        "!./bin/nn_main 20 4 0.5 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Onw-9ukov6kI",
        "outputId": "f95c6c48-c87f-4333-c6c1-4fe6930e8e47",
        "collapsed": true
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASELINE GPU TEST...\n",
            "-- # neurons: 20\n",
            "-- # epochs: 4\n",
            "-- learning rate: 0.5\n",
            "-- optimize GPU (tiled matmul in FW, fp16 in BW): 0\n",
            "Train Images: 60000 with size 784\n",
            "Train Labels: 60000 labels loaded\n",
            "Test Images: 10000 with size 784\n",
            "Test Labels: 10000 labels loaded\n",
            "\n",
            "- layer 0 forward time: 4379.844238 ms\n",
            "- layer 1 forward time: 88.424767 ms\n",
            "- layer 2 forward time: 55.104832 ms\n",
            "> FORWARD TIME CPU: 4523.625000 ms\n",
            "\n",
            "- layer 0 forward time: 53.783936 ms\n",
            "- layer 1 forward time: 5.358496 ms\n",
            "- layer 2 forward time: 2.895040 ms\n",
            "> FORWARD TIME GPU: 66.104355 ms\n",
            "\n",
            "-- Mean error CPU - GPU: 1.23281e-05\n",
            "\n",
            "Training on CPU...\n",
            "- layer 0 forward time: 3048.427734 ms\n",
            "- layer 1 forward time: 88.785919 ms\n",
            "- layer 2 forward time: 55.749695 ms\n",
            ">>> Epoch 1 CEE loss: 13.4511\n",
            "- layer 0 forward time: 3676.557617 ms\n",
            "- layer 1 forward time: 140.046204 ms\n",
            "- layer 2 forward time: 85.972450 ms\n",
            ">>> Epoch 2 CEE loss: 13.3549\n",
            "- layer 0 forward time: 3045.989502 ms\n",
            "- layer 1 forward time: 87.990623 ms\n",
            "- layer 2 forward time: 53.658207 ms\n",
            ">>> Epoch 3 CEE loss: 14.5106\n",
            "- layer 0 forward time: 3986.085449 ms\n",
            "- layer 1 forward time: 87.611549 ms\n",
            "- layer 2 forward time: 53.718143 ms\n",
            ">>> Epoch 4 CEE loss: 12.9161\n",
            "> TRAIN TIME: 32122.548828 ms\n",
            "\n",
            "Training on GPU...\n",
            "- layer 0 forward time: 52.615070 ms\n",
            "- layer 1 forward time: 5.520288 ms\n",
            "- layer 2 forward time: 2.718464 ms\n",
            "- layer 2 backward time: 11.738368 ms\n",
            "- layer 1 backward time: 12.716448 ms\n",
            "- layer 0 backward time: 72.977089 ms\n",
            ">>> Epoch 1 CEE loss: 13.4508\n",
            "- layer 0 forward time: 49.250881 ms\n",
            "- layer 1 forward time: 5.606720 ms\n",
            "- layer 2 forward time: 2.725536 ms\n",
            "- layer 2 backward time: 8.761856 ms\n",
            "- layer 1 backward time: 9.824608 ms\n",
            "- layer 0 backward time: 66.850624 ms\n",
            ">>> Epoch 2 CEE loss: 13.3064\n",
            "- layer 0 forward time: 48.917568 ms\n",
            "- layer 1 forward time: 5.417632 ms\n",
            "- layer 2 forward time: 2.764544 ms\n",
            "- layer 2 backward time: 6.353600 ms\n",
            "- layer 1 backward time: 7.184064 ms\n",
            "- layer 0 backward time: 59.616638 ms\n",
            ">>> Epoch 3 CEE loss: 14.5115\n",
            "- layer 0 forward time: 46.478336 ms\n",
            "- layer 1 forward time: 4.482720 ms\n",
            "- layer 2 forward time: 2.330400 ms\n",
            "- layer 2 backward time: 6.270912 ms\n",
            "- layer 1 backward time: 6.999456 ms\n",
            "- layer 0 backward time: 58.454494 ms\n",
            ">>> Epoch 4 CEE loss: 14.5115\n",
            "> TRAIN TIME: 657.228210 ms\n",
            "\n",
            "Forward on test set, CPU...\n",
            "- layer 0 forward time: 499.701599 ms\n",
            "- layer 1 forward time: 14.262592 ms\n",
            "- layer 2 forward time: 9.134848 ms\n",
            "Forward on test set, GPU...\n",
            "- layer 0 forward time: 8.907680 ms\n",
            "- layer 1 forward time: 0.320640 ms\n",
            "- layer 2 forward time: 0.269856 ms\n",
            "-- Mean error CPU - GPU: 1.68979e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"OPTIMIZED GPU TEST...\"\n",
        "!./bin/nn_main 20 4 0.5 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfZrAoPAv-GA",
        "outputId": "0eae5607-a67f-43f3-a8c1-b2d1ac699e98"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPTIMIZED GPU TEST...\n",
            "-- # neurons: 20\n",
            "-- # epochs: 4\n",
            "-- learning rate: 0.5\n",
            "-- optimize GPU (tiled matmul in FW, fp16 in BW): 1\n",
            "Train Images: 60000 with size 784\n",
            "Train Labels: 60000 labels loaded\n",
            "Test Images: 10000 with size 784\n",
            "Test Labels: 10000 labels loaded\n",
            "\n",
            "- layer 0 forward time: 4251.382812 ms\n",
            "- layer 1 forward time: 98.322815 ms\n",
            "- layer 2 forward time: 55.277599 ms\n",
            "> FORWARD TIME CPU: 4405.264648 ms\n",
            "\n",
            "- layer 0 forward time: 51.730656 ms\n",
            "- layer 1 forward time: 5.418880 ms\n",
            "- layer 2 forward time: 2.607744 ms\n",
            "> FORWARD TIME GPU: 63.684673 ms\n",
            "\n",
            "-- Mean error CPU - GPU: 8.18262e-06\n",
            "\n",
            "Training on CPU...\n",
            "- layer 0 forward time: 3013.743408 ms\n",
            "- layer 1 forward time: 88.179619 ms\n",
            "- layer 2 forward time: 54.590782 ms\n",
            ">>> Epoch 1 CEE loss: 13.4511\n",
            "- layer 0 forward time: 4375.395996 ms\n",
            "- layer 1 forward time: 89.246338 ms\n",
            "- layer 2 forward time: 64.704514 ms\n",
            ">>> Epoch 2 CEE loss: 13.3549\n",
            "- layer 0 forward time: 3020.679199 ms\n",
            "- layer 1 forward time: 88.342880 ms\n",
            "- layer 2 forward time: 53.762047 ms\n",
            ">>> Epoch 3 CEE loss: 14.5106\n",
            "- layer 0 forward time: 3119.439697 ms\n",
            "- layer 1 forward time: 92.601471 ms\n",
            "- layer 2 forward time: 54.035873 ms\n",
            ">>> Epoch 4 CEE loss: 12.9161\n",
            "> TRAIN TIME: 32078.226562 ms\n",
            "\n",
            "Training on GPU...\n",
            "- layer 0 forward time: 52.263680 ms\n",
            "- layer 1 forward time: 5.530464 ms\n",
            "- layer 2 forward time: 2.689440 ms\n",
            "- layer 2 FP16 backward time: 12.148064 ms\n",
            "- layer 1 FP16 backward time: 13.486240 ms\n",
            "- layer 0 FP16 backward time: 40.820896 ms\n",
            ">>> Epoch 1 CEE loss: 13.4507\n",
            "- layer 0 forward time: 50.637890 ms\n",
            "- layer 1 forward time: 5.464736 ms\n",
            "- layer 2 forward time: 2.907424 ms\n",
            "- layer 2 FP16 backward time: 10.654848 ms\n",
            "- layer 1 FP16 backward time: 12.009696 ms\n",
            "- layer 0 FP16 backward time: 34.212994 ms\n",
            ">>> Epoch 2 CEE loss: 13.4029\n",
            "- layer 0 forward time: 55.084766 ms\n",
            "- layer 1 forward time: 6.312512 ms\n",
            "- layer 2 forward time: 2.507840 ms\n",
            "- layer 2 FP16 backward time: 10.144672 ms\n",
            "- layer 1 FP16 backward time: 11.460608 ms\n",
            "- layer 0 FP16 backward time: 31.475296 ms\n",
            ">>> Epoch 3 CEE loss: 13.3526\n",
            "- layer 0 forward time: 59.561600 ms\n",
            "- layer 1 forward time: 6.409408 ms\n",
            "- layer 2 forward time: 3.187232 ms\n",
            "- layer 2 FP16 backward time: 12.402656 ms\n",
            "- layer 1 FP16 backward time: 13.451008 ms\n",
            "- layer 0 FP16 backward time: 38.370850 ms\n",
            ">>> Epoch 4 CEE loss: 13.299\n",
            "> TRAIN TIME: 6579.337891 ms\n",
            "\n",
            "Forward on test set, CPU...\n",
            "- layer 0 forward time: 512.315002 ms\n",
            "- layer 1 forward time: 15.575232 ms\n",
            "- layer 2 forward time: 9.429152 ms\n",
            "Forward on test set, GPU...\n",
            "- layer 0 forward time: 8.580480 ms\n",
            "- layer 1 forward time: 0.482432 ms\n",
            "- layer 2 forward time: 0.336608 ms\n",
            "-- Mean error CPU - GPU: 0.19997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"CPU-GPU Dual train test...\"\n",
        "!./bin/nn_main 20 20 0.5 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foLuDPOf5tYQ",
        "outputId": "b4b8da22-a55e-4990-edef-f507ffdae0d3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU-GPU Dual train test...\n",
            "-- # neurons: 20\n",
            "-- # epochs: 20\n",
            "-- learning rate: 0.5\n",
            "-- optimize GPU (tiled matmul in FW, fp16 in BW): 0\n",
            "Train Images: 60000 with size 784\n",
            "Train Labels: 60000 labels loaded\n",
            "Test Images: 10000 with size 784\n",
            "Test Labels: 10000 labels loaded\n",
            "\n",
            "- layer 0 forward time: 3319.694092 ms\n",
            "- layer 1 forward time: 141.525375 ms\n",
            "- layer 2 forward time: 86.575104 ms\n",
            "> FORWARD TIME CPU: 3548.024902 ms\n",
            "\n",
            "- layer 0 forward time: 60.542976 ms\n",
            "- layer 1 forward time: 6.197664 ms\n",
            "- layer 2 forward time: 3.332960 ms\n",
            "> FORWARD TIME GPU: 75.262115 ms\n",
            "\n",
            "-- Mean error CPU - GPU: 2.104e-05\n",
            "\n",
            "Training on CPU...\n",
            "- layer 0 forward time: 3903.070068 ms\n",
            "- layer 1 forward time: 88.365059 ms\n",
            "- layer 2 forward time: 56.622082 ms\n",
            ">>> Epoch 1 CEE loss: 13.4511\n",
            "- layer 0 forward time: 3025.088135 ms\n",
            "- layer 1 forward time: 88.295166 ms\n",
            "- layer 2 forward time: 54.308353 ms\n",
            ">>> Epoch 2 CEE loss: 13.3549\n",
            "- layer 0 forward time: 3011.146484 ms\n",
            "- layer 1 forward time: 97.058495 ms\n",
            "- layer 2 forward time: 55.066814 ms\n",
            ">>> Epoch 3 CEE loss: 14.5106\n",
            "- layer 0 forward time: 4367.148926 ms\n",
            "- layer 1 forward time: 88.549507 ms\n",
            "- layer 2 forward time: 55.302689 ms\n",
            ">>> Epoch 4 CEE loss: 12.9161\n",
            "- layer 0 forward time: 3027.129395 ms\n",
            "- layer 1 forward time: 88.125565 ms\n",
            "- layer 2 forward time: 55.166401 ms\n",
            ">>> Epoch 5 CEE loss: 14.5097\n",
            "- layer 0 forward time: 3069.233643 ms\n",
            "- layer 1 forward time: 94.526337 ms\n",
            "- layer 2 forward time: 57.880928 ms\n",
            ">>> Epoch 6 CEE loss: 12.9317\n",
            "- layer 0 forward time: 3319.130615 ms\n",
            "- layer 1 forward time: 140.776413 ms\n",
            "- layer 2 forward time: 90.008064 ms\n",
            ">>> Epoch 7 CEE loss: 13.1388\n",
            "- layer 0 forward time: 3022.299805 ms\n",
            "- layer 1 forward time: 87.846748 ms\n",
            "- layer 2 forward time: 53.200703 ms\n",
            ">>> Epoch 8 CEE loss: 12.9277\n",
            "- layer 0 forward time: 4137.948730 ms\n",
            "- layer 1 forward time: 88.051392 ms\n",
            "- layer 2 forward time: 53.537567 ms\n",
            ">>> Epoch 9 CEE loss: 14.5022\n",
            "- layer 0 forward time: 3010.693604 ms\n",
            "- layer 1 forward time: 88.243011 ms\n",
            "- layer 2 forward time: 55.162018 ms\n",
            ">>> Epoch 10 CEE loss: 14.4882\n",
            "- layer 0 forward time: 3008.609375 ms\n",
            "- layer 1 forward time: 90.433151 ms\n",
            "- layer 2 forward time: 62.276482 ms\n",
            ">>> Epoch 11 CEE loss: 14.5115\n",
            "- layer 0 forward time: 4275.367188 ms\n",
            "- layer 1 forward time: 141.084381 ms\n",
            "- layer 2 forward time: 79.099426 ms\n",
            ">>> Epoch 12 CEE loss: 11.6379\n",
            "- layer 0 forward time: 3009.824463 ms\n",
            "- layer 1 forward time: 88.381119 ms\n",
            "- layer 2 forward time: 55.709377 ms\n",
            ">>> Epoch 13 CEE loss: 11.3088\n",
            "- layer 0 forward time: 3209.051758 ms\n",
            "- layer 1 forward time: 88.300385 ms\n",
            "- layer 2 forward time: 54.361153 ms\n",
            ">>> Epoch 14 CEE loss: 14.5055\n",
            "- layer 0 forward time: 3135.500488 ms\n",
            "- layer 1 forward time: 137.498367 ms\n",
            "- layer 2 forward time: 85.246590 ms\n",
            ">>> Epoch 15 CEE loss: 6.24135\n",
            "- layer 0 forward time: 3055.358154 ms\n",
            "- layer 1 forward time: 88.644707 ms\n",
            "- layer 2 forward time: 54.501663 ms\n",
            ">>> Epoch 16 CEE loss: 12.1924\n",
            "- layer 0 forward time: 4299.491699 ms\n",
            "- layer 1 forward time: 88.165886 ms\n",
            "- layer 2 forward time: 56.536224 ms\n",
            ">>> Epoch 17 CEE loss: 13.3993\n",
            "- layer 0 forward time: 3041.367676 ms\n",
            "- layer 1 forward time: 87.851166 ms\n",
            "- layer 2 forward time: 54.279713 ms\n",
            ">>> Epoch 18 CEE loss: 6.17185\n",
            "- layer 0 forward time: 3052.262451 ms\n",
            "- layer 1 forward time: 88.159485 ms\n",
            "- layer 2 forward time: 54.751678 ms\n",
            ">>> Epoch 19 CEE loss: 9.79925\n",
            "- layer 0 forward time: 4077.288818 ms\n",
            "- layer 1 forward time: 145.705536 ms\n",
            "- layer 2 forward time: 94.508324 ms\n",
            ">>> Epoch 20 CEE loss: 11.2443\n",
            "> TRAIN TIME: 164411.531250 ms\n",
            "\n",
            "Training on GPU...\n",
            "- layer 0 forward time: 52.453983 ms\n",
            "- layer 1 forward time: 5.587520 ms\n",
            "- layer 2 forward time: 2.746016 ms\n",
            "- layer 2 backward time: 11.809536 ms\n",
            "- layer 1 backward time: 13.104160 ms\n",
            "- layer 0 backward time: 73.008995 ms\n",
            ">>> Epoch 1 CEE loss: 13.451\n",
            "- layer 0 forward time: 52.685055 ms\n",
            "- layer 1 forward time: 5.696768 ms\n",
            "- layer 2 forward time: 2.810912 ms\n",
            "- layer 2 backward time: 11.792480 ms\n",
            "- layer 1 backward time: 12.943008 ms\n",
            "- layer 0 backward time: 72.556770 ms\n",
            ">>> Epoch 2 CEE loss: 13.3068\n",
            "- layer 0 forward time: 49.692097 ms\n",
            "- layer 1 forward time: 5.503360 ms\n",
            "- layer 2 forward time: 2.524096 ms\n",
            "- layer 2 backward time: 7.780544 ms\n",
            "- layer 1 backward time: 8.871264 ms\n",
            "- layer 0 backward time: 62.939938 ms\n",
            ">>> Epoch 3 CEE loss: 14.5115\n",
            "- layer 0 forward time: 48.306561 ms\n",
            "- layer 1 forward time: 5.380288 ms\n",
            "- layer 2 forward time: 2.471040 ms\n",
            "- layer 2 backward time: 10.565792 ms\n",
            "- layer 1 backward time: 8.070624 ms\n",
            "- layer 0 backward time: 59.992256 ms\n",
            ">>> Epoch 4 CEE loss: 14.5115\n",
            "- layer 0 forward time: 50.405537 ms\n",
            "- layer 1 forward time: 4.730368 ms\n",
            "- layer 2 forward time: 2.809344 ms\n",
            "- layer 2 backward time: 5.984800 ms\n",
            "- layer 1 backward time: 6.511264 ms\n",
            "- layer 0 backward time: 58.111519 ms\n",
            ">>> Epoch 5 CEE loss: 14.5115\n",
            "- layer 0 forward time: 46.431488 ms\n",
            "- layer 1 forward time: 3.863520 ms\n",
            "- layer 2 forward time: 2.340000 ms\n",
            "- layer 2 backward time: 5.685760 ms\n",
            "- layer 1 backward time: 6.308480 ms\n",
            "- layer 0 backward time: 57.469280 ms\n",
            ">>> Epoch 6 CEE loss: 14.5115\n",
            "- layer 0 forward time: 46.344959 ms\n",
            "- layer 1 forward time: 3.775776 ms\n",
            "- layer 2 forward time: 2.334496 ms\n",
            "- layer 2 backward time: 5.673280 ms\n",
            "- layer 1 backward time: 6.368288 ms\n",
            "- layer 0 backward time: 58.294655 ms\n",
            ">>> Epoch 7 CEE loss: 14.5115\n",
            "- layer 0 forward time: 46.696865 ms\n",
            "- layer 1 forward time: 3.841824 ms\n",
            "- layer 2 forward time: 2.390432 ms\n",
            "- layer 2 backward time: 5.720864 ms\n",
            "- layer 1 backward time: 6.392576 ms\n",
            "- layer 0 backward time: 57.596767 ms\n",
            ">>> Epoch 8 CEE loss: 3.5906\n",
            "- layer 0 forward time: 47.472607 ms\n",
            "- layer 1 forward time: 3.791328 ms\n",
            "- layer 2 forward time: 2.394752 ms\n",
            "- layer 2 backward time: 5.684064 ms\n",
            "- layer 1 backward time: 6.365888 ms\n",
            "- layer 0 backward time: 58.461887 ms\n",
            ">>> Epoch 9 CEE loss: 8.87002\n",
            "- layer 0 forward time: 46.867970 ms\n",
            "- layer 1 forward time: 3.721472 ms\n",
            "- layer 2 forward time: 2.530176 ms\n",
            "- layer 2 backward time: 5.827040 ms\n",
            "- layer 1 backward time: 6.326976 ms\n",
            "- layer 0 backward time: 57.149506 ms\n",
            ">>> Epoch 10 CEE loss: 3.59066\n",
            "- layer 0 forward time: 46.334560 ms\n",
            "- layer 1 forward time: 3.699680 ms\n",
            "- layer 2 forward time: 2.304928 ms\n",
            "- layer 2 backward time: 5.643936 ms\n",
            "- layer 1 backward time: 6.274656 ms\n",
            "- layer 0 backward time: 58.760033 ms\n",
            ">>> Epoch 11 CEE loss: 8.87012\n",
            "- layer 0 forward time: 50.793598 ms\n",
            "- layer 1 forward time: 3.727488 ms\n",
            "- layer 2 forward time: 2.296608 ms\n",
            "- layer 2 backward time: 5.645728 ms\n",
            "- layer 1 backward time: 6.300544 ms\n",
            "- layer 0 backward time: 57.117249 ms\n",
            ">>> Epoch 12 CEE loss: 8.86999\n",
            "- layer 0 forward time: 46.317696 ms\n",
            "- layer 1 forward time: 3.630784 ms\n",
            "- layer 2 forward time: 2.224032 ms\n",
            "- layer 2 backward time: 5.586400 ms\n",
            "- layer 1 backward time: 6.219200 ms\n",
            "- layer 0 backward time: 57.522751 ms\n",
            ">>> Epoch 13 CEE loss: 2.29714\n",
            "- layer 0 forward time: 47.099392 ms\n",
            "- layer 1 forward time: 3.682336 ms\n",
            "- layer 2 forward time: 2.230176 ms\n",
            "- layer 2 backward time: 5.540192 ms\n",
            "- layer 1 backward time: 6.287840 ms\n",
            "- layer 0 backward time: 57.445438 ms\n",
            ">>> Epoch 14 CEE loss: 11.6173\n",
            "- layer 0 forward time: 46.593983 ms\n",
            "- layer 1 forward time: 3.681120 ms\n",
            "- layer 2 forward time: 2.220128 ms\n",
            "- layer 2 backward time: 5.574912 ms\n",
            "- layer 1 backward time: 6.201760 ms\n",
            "- layer 0 backward time: 57.711521 ms\n",
            ">>> Epoch 15 CEE loss: 3.85077\n",
            "- layer 0 forward time: 46.842850 ms\n",
            "- layer 1 forward time: 3.586400 ms\n",
            "- layer 2 forward time: 2.200800 ms\n",
            "- layer 2 backward time: 5.564512 ms\n",
            "- layer 1 backward time: 6.358752 ms\n",
            "- layer 0 backward time: 58.092384 ms\n",
            ">>> Epoch 16 CEE loss: 2.30269\n",
            "- layer 0 forward time: 46.513058 ms\n",
            "- layer 1 forward time: 3.586400 ms\n",
            "- layer 2 forward time: 2.190560 ms\n",
            "- layer 2 backward time: 5.561696 ms\n",
            "- layer 1 backward time: 6.173920 ms\n",
            "- layer 0 backward time: 57.899487 ms\n",
            ">>> Epoch 17 CEE loss: 6.22253\n",
            "- layer 0 forward time: 46.164928 ms\n",
            "- layer 1 forward time: 3.824640 ms\n",
            "- layer 2 forward time: 2.226784 ms\n",
            "- layer 2 backward time: 5.543232 ms\n",
            "- layer 1 backward time: 6.133760 ms\n",
            "- layer 0 backward time: 57.491905 ms\n",
            ">>> Epoch 18 CEE loss: 2.30296\n",
            "- layer 0 forward time: 49.078079 ms\n",
            "- layer 1 forward time: 3.930592 ms\n",
            "- layer 2 forward time: 2.262176 ms\n",
            "- layer 2 backward time: 5.571584 ms\n",
            "- layer 1 backward time: 6.173728 ms\n",
            "- layer 0 backward time: 57.070976 ms\n",
            ">>> Epoch 19 CEE loss: 2.30311\n",
            "- layer 0 forward time: 46.898174 ms\n",
            "- layer 1 forward time: 3.656768 ms\n",
            "- layer 2 forward time: 2.191296 ms\n",
            "- layer 2 backward time: 5.517536 ms\n",
            "- layer 1 backward time: 6.117472 ms\n",
            "- layer 0 backward time: 57.142368 ms\n",
            ">>> Epoch 20 CEE loss: 8.84415\n",
            "> TRAIN TIME: 3041.145508 ms\n",
            "\n",
            "Forward on test set, CPU...\n",
            "- layer 0 forward time: 501.685577 ms\n",
            "- layer 1 forward time: 14.869952 ms\n",
            "- layer 2 forward time: 9.171520 ms\n",
            "Forward on test set, GPU...\n",
            "- layer 0 forward time: 8.850336 ms\n",
            "- layer 1 forward time: 0.311808 ms\n",
            "- layer 2 forward time: 0.263072 ms\n",
            "-- Mean error CPU - GPU: 0.156931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"CPU-GPU Dual train test...\"\n",
        "!./bin/nn_main 20 20 0.5 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLiVvEnR3DBB",
        "outputId": "89a52d3f-64d2-4d30-c8db-b27dca5d6c0a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU-GPU Dual train test...\n",
            "-- # neurons: 20\n",
            "-- # epochs: 20\n",
            "-- learning rate: 0.5\n",
            "-- optimize GPU (tiled matmul in FW, fp16 in BW): 1\n",
            "Train Images: 60000 with size 784\n",
            "Train Labels: 60000 labels loaded\n",
            "Test Images: 10000 with size 784\n",
            "Test Labels: 10000 labels loaded\n",
            "\n",
            "- layer 0 forward time: 3066.692871 ms\n",
            "- layer 1 forward time: 88.674301 ms\n",
            "- layer 2 forward time: 57.085377 ms\n",
            "> FORWARD TIME CPU: 3212.644043 ms\n",
            "\n",
            "- layer 0 forward time: 51.936928 ms\n",
            "- layer 1 forward time: 5.931936 ms\n",
            "- layer 2 forward time: 2.697984 ms\n",
            "> FORWARD TIME GPU: 65.409950 ms\n",
            "\n",
            "-- Mean error CPU - GPU: 1.17953e-05\n",
            "\n",
            "Training on CPU...\n",
            "- layer 0 forward time: 3116.512207 ms\n",
            "- layer 1 forward time: 88.229507 ms\n",
            "- layer 2 forward time: 57.950657 ms\n",
            ">>> Epoch 1 CEE loss: 13.4511\n",
            "- layer 0 forward time: 3035.551758 ms\n",
            "- layer 1 forward time: 90.678146 ms\n",
            "- layer 2 forward time: 54.158878 ms\n",
            ">>> Epoch 2 CEE loss: 13.3549\n",
            "- layer 0 forward time: 4352.062500 ms\n",
            "- layer 1 forward time: 88.648735 ms\n",
            "- layer 2 forward time: 53.673119 ms\n",
            ">>> Epoch 3 CEE loss: 14.5106\n",
            "- layer 0 forward time: 3050.986328 ms\n",
            "- layer 1 forward time: 91.962242 ms\n",
            "- layer 2 forward time: 57.439968 ms\n",
            ">>> Epoch 4 CEE loss: 12.9161\n",
            "- layer 0 forward time: 3008.420410 ms\n",
            "- layer 1 forward time: 88.504128 ms\n",
            "- layer 2 forward time: 55.240673 ms\n",
            ">>> Epoch 5 CEE loss: 14.5097\n",
            "- layer 0 forward time: 3881.131348 ms\n",
            "- layer 1 forward time: 140.246597 ms\n",
            "- layer 2 forward time: 94.174942 ms\n",
            ">>> Epoch 6 CEE loss: 12.9317\n",
            "- layer 0 forward time: 3068.248779 ms\n",
            "- layer 1 forward time: 88.064003 ms\n",
            "- layer 2 forward time: 54.997089 ms\n",
            ">>> Epoch 7 CEE loss: 13.1388\n",
            "- layer 0 forward time: 3795.367432 ms\n",
            "- layer 1 forward time: 88.567619 ms\n",
            "- layer 2 forward time: 53.219776 ms\n",
            ">>> Epoch 8 CEE loss: 12.9277\n",
            "- layer 0 forward time: 3031.604980 ms\n",
            "- layer 1 forward time: 88.460098 ms\n",
            "- layer 2 forward time: 53.013729 ms\n",
            ">>> Epoch 9 CEE loss: 14.5022\n",
            "- layer 0 forward time: 3014.493652 ms\n",
            "- layer 1 forward time: 88.063744 ms\n",
            "- layer 2 forward time: 54.682304 ms\n",
            ">>> Epoch 10 CEE loss: 14.4882\n",
            "- layer 0 forward time: 4350.632324 ms\n",
            "- layer 1 forward time: 96.913986 ms\n",
            "- layer 2 forward time: 54.200161 ms\n",
            ">>> Epoch 11 CEE loss: 14.5115\n",
            "- layer 0 forward time: 3022.829590 ms\n",
            "- layer 1 forward time: 104.357437 ms\n",
            "- layer 2 forward time: 56.526402 ms\n",
            ">>> Epoch 12 CEE loss: 11.6379\n",
            "- layer 0 forward time: 3015.845703 ms\n",
            "- layer 1 forward time: 89.425308 ms\n",
            "- layer 2 forward time: 57.220993 ms\n",
            ">>> Epoch 13 CEE loss: 11.3088\n",
            "- layer 0 forward time: 3794.992676 ms\n",
            "- layer 1 forward time: 141.393539 ms\n",
            "- layer 2 forward time: 88.963936 ms\n",
            ">>> Epoch 14 CEE loss: 14.5055\n",
            "- layer 0 forward time: 3040.330811 ms\n",
            "- layer 1 forward time: 90.008255 ms\n",
            "- layer 2 forward time: 57.124512 ms\n",
            ">>> Epoch 15 CEE loss: 6.24135\n",
            "- layer 0 forward time: 3681.447266 ms\n",
            "- layer 1 forward time: 87.979042 ms\n",
            "- layer 2 forward time: 55.251999 ms\n",
            ">>> Epoch 16 CEE loss: 12.1924\n",
            "- layer 0 forward time: 3036.519775 ms\n",
            "- layer 1 forward time: 90.091965 ms\n",
            "- layer 2 forward time: 55.490017 ms\n",
            ">>> Epoch 17 CEE loss: 13.3993\n",
            "- layer 0 forward time: 3012.432617 ms\n",
            "- layer 1 forward time: 89.140862 ms\n",
            "- layer 2 forward time: 55.434464 ms\n",
            ">>> Epoch 18 CEE loss: 6.17185\n",
            "- layer 0 forward time: 4317.586914 ms\n",
            "- layer 1 forward time: 89.405060 ms\n",
            "- layer 2 forward time: 55.812286 ms\n",
            ">>> Epoch 19 CEE loss: 9.79925\n",
            "- layer 0 forward time: 3026.847412 ms\n",
            "- layer 1 forward time: 88.985245 ms\n",
            "- layer 2 forward time: 55.529247 ms\n",
            ">>> Epoch 20 CEE loss: 11.2443\n",
            "> TRAIN TIME: 165816.296875 ms\n",
            "\n",
            "Training on GPU...\n",
            "- layer 0 forward time: 50.602753 ms\n",
            "- layer 1 forward time: 6.276480 ms\n",
            "- layer 2 forward time: 2.756064 ms\n",
            "- layer 2 FP16 backward time: 12.172384 ms\n",
            "- layer 1 FP16 backward time: 14.076512 ms\n",
            "- layer 0 FP16 backward time: 41.069408 ms\n",
            ">>> Epoch 1 CEE loss: 13.4507\n",
            "- layer 0 forward time: 50.957825 ms\n",
            "- layer 1 forward time: 5.526592 ms\n",
            "- layer 2 forward time: 2.703840 ms\n",
            "- layer 2 FP16 backward time: 10.206688 ms\n",
            "- layer 1 FP16 backward time: 11.870720 ms\n",
            "- layer 0 FP16 backward time: 33.317024 ms\n",
            ">>> Epoch 2 CEE loss: 13.4033\n",
            "- layer 0 forward time: 49.508961 ms\n",
            "- layer 1 forward time: 5.442144 ms\n",
            "- layer 2 forward time: 2.553600 ms\n",
            "- layer 2 FP16 backward time: 9.713088 ms\n",
            "- layer 1 FP16 backward time: 11.062432 ms\n",
            "- layer 0 FP16 backward time: 30.142496 ms\n",
            ">>> Epoch 3 CEE loss: 13.3525\n",
            "- layer 0 forward time: 48.045727 ms\n",
            "- layer 1 forward time: 5.252704 ms\n",
            "- layer 2 forward time: 2.370080 ms\n",
            "- layer 2 FP16 backward time: 9.526048 ms\n",
            "- layer 1 FP16 backward time: 10.861312 ms\n",
            "- layer 0 FP16 backward time: 29.511841 ms\n",
            ">>> Epoch 4 CEE loss: 13.2991\n",
            "- layer 0 forward time: 47.829887 ms\n",
            "- layer 1 forward time: 5.252928 ms\n",
            "- layer 2 forward time: 2.549632 ms\n",
            "- layer 2 FP16 backward time: 11.959712 ms\n",
            "- layer 1 FP16 backward time: 13.517568 ms\n",
            "- layer 0 FP16 backward time: 38.586208 ms\n",
            ">>> Epoch 5 CEE loss: 13.2423\n",
            "- layer 0 forward time: 52.068863 ms\n",
            "- layer 1 forward time: 5.328000 ms\n",
            "- layer 2 forward time: 2.542176 ms\n",
            "- layer 2 FP16 backward time: 11.979392 ms\n",
            "- layer 1 FP16 backward time: 13.399936 ms\n",
            "- layer 0 FP16 backward time: 38.226528 ms\n",
            ">>> Epoch 6 CEE loss: 13.182\n",
            "- layer 0 forward time: 50.332832 ms\n",
            "- layer 1 forward time: 5.329856 ms\n",
            "- layer 2 forward time: 2.567264 ms\n",
            "- layer 2 FP16 backward time: 11.366144 ms\n",
            "- layer 1 FP16 backward time: 12.835040 ms\n",
            "- layer 0 FP16 backward time: 36.258495 ms\n",
            ">>> Epoch 7 CEE loss: 13.1187\n",
            "- layer 0 forward time: 55.098110 ms\n",
            "- layer 1 forward time: 6.368096 ms\n",
            "- layer 2 forward time: 3.141568 ms\n",
            "- layer 2 FP16 backward time: 12.902720 ms\n",
            "- layer 1 FP16 backward time: 15.605696 ms\n",
            "- layer 0 FP16 backward time: 38.792130 ms\n",
            ">>> Epoch 8 CEE loss: 13.0527\n",
            "- layer 0 forward time: 56.095936 ms\n",
            "- layer 1 forward time: 6.436576 ms\n",
            "- layer 2 forward time: 3.180160 ms\n",
            "- layer 2 FP16 backward time: 12.076224 ms\n",
            "- layer 1 FP16 backward time: 13.399520 ms\n",
            "- layer 0 FP16 backward time: 38.369217 ms\n",
            ">>> Epoch 9 CEE loss: 12.9838\n",
            "- layer 0 forward time: 50.857086 ms\n",
            "- layer 1 forward time: 5.383872 ms\n",
            "- layer 2 forward time: 2.553472 ms\n",
            "- layer 2 FP16 backward time: 12.003456 ms\n",
            "- layer 1 FP16 backward time: 13.404672 ms\n",
            "- layer 0 FP16 backward time: 38.235134 ms\n",
            ">>> Epoch 10 CEE loss: 12.9118\n",
            "- layer 0 forward time: 50.346977 ms\n",
            "- layer 1 forward time: 5.340160 ms\n",
            "- layer 2 forward time: 2.546176 ms\n",
            "- layer 2 FP16 backward time: 12.023616 ms\n",
            "- layer 1 FP16 backward time: 13.410176 ms\n",
            "- layer 0 FP16 backward time: 38.479519 ms\n",
            ">>> Epoch 11 CEE loss: 12.8367\n",
            "- layer 0 forward time: 50.535263 ms\n",
            "- layer 1 forward time: 5.383360 ms\n",
            "- layer 2 forward time: 2.668640 ms\n",
            "- layer 2 FP16 backward time: 12.157632 ms\n",
            "- layer 1 FP16 backward time: 13.365856 ms\n",
            "- layer 0 FP16 backward time: 38.468735 ms\n",
            ">>> Epoch 12 CEE loss: 12.7577\n",
            "- layer 0 forward time: 52.906654 ms\n",
            "- layer 1 forward time: 5.356768 ms\n",
            "- layer 2 forward time: 2.531296 ms\n",
            "- layer 2 FP16 backward time: 12.025728 ms\n",
            "- layer 1 FP16 backward time: 13.518720 ms\n",
            "- layer 0 FP16 backward time: 38.283615 ms\n",
            ">>> Epoch 13 CEE loss: 12.676\n",
            "- layer 0 forward time: 51.902176 ms\n",
            "- layer 1 forward time: 5.377408 ms\n",
            "- layer 2 forward time: 2.512800 ms\n",
            "- layer 2 FP16 backward time: 11.955136 ms\n",
            "- layer 1 FP16 backward time: 13.596928 ms\n",
            "- layer 0 FP16 backward time: 38.270752 ms\n",
            ">>> Epoch 14 CEE loss: 12.5888\n",
            "- layer 0 forward time: 51.096958 ms\n",
            "- layer 1 forward time: 5.380704 ms\n",
            "- layer 2 forward time: 3.158240 ms\n",
            "- layer 2 FP16 backward time: 11.972704 ms\n",
            "- layer 1 FP16 backward time: 13.353088 ms\n",
            "- layer 0 FP16 backward time: 38.306786 ms\n",
            ">>> Epoch 15 CEE loss: 12.4962\n",
            "- layer 0 forward time: 50.827202 ms\n",
            "- layer 1 forward time: 5.372768 ms\n",
            "- layer 2 forward time: 2.520352 ms\n",
            "- layer 2 FP16 backward time: 11.030784 ms\n",
            "- layer 1 FP16 backward time: 12.376992 ms\n",
            "- layer 0 FP16 backward time: 36.442177 ms\n",
            ">>> Epoch 16 CEE loss: 12.3994\n",
            "- layer 0 forward time: 52.176449 ms\n",
            "- layer 1 forward time: 6.369248 ms\n",
            "- layer 2 forward time: 3.033248 ms\n",
            "- layer 2 FP16 backward time: 12.301952 ms\n",
            "- layer 1 FP16 backward time: 14.091072 ms\n",
            "- layer 0 FP16 backward time: 38.977154 ms\n",
            ">>> Epoch 17 CEE loss: 12.2954\n",
            "- layer 0 forward time: 54.914528 ms\n",
            "- layer 1 forward time: 6.584032 ms\n",
            "- layer 2 forward time: 3.276352 ms\n",
            "- layer 2 FP16 backward time: 11.280288 ms\n",
            "- layer 1 FP16 backward time: 12.380992 ms\n",
            "- layer 0 FP16 backward time: 35.004002 ms\n",
            ">>> Epoch 18 CEE loss: 12.1871\n",
            "- layer 0 forward time: 50.112000 ms\n",
            "- layer 1 forward time: 5.320192 ms\n",
            "- layer 2 forward time: 2.478048 ms\n",
            "- layer 2 FP16 backward time: 12.168864 ms\n",
            "- layer 1 FP16 backward time: 13.958656 ms\n",
            "- layer 0 FP16 backward time: 38.681854 ms\n",
            ">>> Epoch 19 CEE loss: 12.0746\n",
            "- layer 0 forward time: 50.444447 ms\n",
            "- layer 1 forward time: 5.358752 ms\n",
            "- layer 2 forward time: 2.507616 ms\n",
            "- layer 2 FP16 backward time: 12.036832 ms\n",
            "- layer 1 FP16 backward time: 13.439616 ms\n",
            "- layer 0 FP16 backward time: 38.509792 ms\n",
            ">>> Epoch 20 CEE loss: 11.9587\n",
            "> TRAIN TIME: 30068.183594 ms\n",
            "\n",
            "Forward on test set, CPU...\n",
            "- layer 0 forward time: 515.910522 ms\n",
            "- layer 1 forward time: 15.681120 ms\n",
            "- layer 2 forward time: 9.172096 ms\n",
            "Forward on test set, GPU...\n",
            "- layer 0 forward time: 8.547264 ms\n",
            "- layer 1 forward time: 0.510176 ms\n",
            "- layer 2 forward time: 0.327616 ms\n",
            "-- Mean error CPU - GPU: 0.171078\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "JxobDUCcMqgs"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}